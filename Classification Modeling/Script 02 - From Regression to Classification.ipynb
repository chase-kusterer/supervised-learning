{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<br><h2>Script 02 | From Regression to Classification</h2>\n",
    "<br>\n",
    "Written by Chase Kusterer<br>\n",
    "<a href=\"https://github.com/chase-kusterer\">GitHub</a> | <a href=\"https://www.linkedin.com/in/kusterer/\">LinkedIn</a>\n",
    "<br><br><br>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<h2>Part I: Preparation and Exploration</h2>\n",
    "<br><h4>a) Imports and Loading the Dataset</h4>\n",
    "Run the code below to import packages and load the 'titanic_feature_rich.xlsx' dataset into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import numpy             as np  # mathematical essentials\n",
    "import pandas            as pd  # data science essentials\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn           as sns # enhanced data viz\n",
    "\n",
    "# classification-specific libraries\n",
    "import phik                           # phi coefficient\n",
    "import statsmodels.formula.api as smf # logistic regression\n",
    "import sklearn.linear_model           # logistic regression\n",
    "\n",
    "\n",
    "# preprocessing and testing\n",
    "from sklearn.preprocessing import power_transform    # yeo-johnson\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             roc_auc_score, precision_score, recall_score)\n",
    "\n",
    "\n",
    "# loading data\n",
    "titanic = pd.read_excel('./datasets/titanic_feature_rich.xlsx')\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "# displaying the head of the dataset\n",
    "titanic.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<strong>User-Defined Functions</strong><br>\n",
    "Run the following code to load the user-defined functions used throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     39
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# standard_scaler\n",
    "########################################\n",
    "def standard_scaler(df):\n",
    "    \"\"\"\n",
    "    Standardizes a dataset (mean = 0, variance = 1). Returns a new DataFrame.\n",
    "    Requires sklearn.preprocessing.StandardScaler()\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df     | DataFrame to be used for scaling\n",
    "    \"\"\"\n",
    "\n",
    "    # INSTANTIATING a StandardScaler() object\n",
    "    scaler = StandardScaler(copy = True)\n",
    "\n",
    "\n",
    "    # FITTING the scaler with the data\n",
    "    scaler.fit(df)\n",
    "\n",
    "\n",
    "    # TRANSFORMING our data after fit\n",
    "    x_scaled = scaler.transform(df)\n",
    "\n",
    "    \n",
    "    # converting scaled data into a DataFrame\n",
    "    new_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "    # reattaching column names\n",
    "    new_df.columns = list(df.columns)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "## visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "    Creates a visualization of a confusion matrix.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    true_y : true values for the response variable\n",
    "    pred_y : predicted values for the response variable\n",
    "    labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part II - Response Variable Analysis</h2><br>\n",
    "Run the following codes to generate survival proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# proportion of 1s and 0s for survived\n",
    "titanic.value_counts(subset    = 'survived',\n",
    "                     normalize = True      ).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# proportion of 1s and 0s\n",
    "female_passengers = titanic[ titanic['female'] == 1 ]\n",
    "\n",
    "female_passengers.value_counts(\n",
    "    subset    = 'survived',\n",
    "    normalize = True      ).round(decimals = 2).sort_index(ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# proportion of 1s and 0s\n",
    "male_passengers = titanic[ titanic['female'] == 0 ]\n",
    "\n",
    "male_passengers.value_counts(\n",
    "    subset    = 'survived',\n",
    "    normalize = True      ).round(decimals = 2).sort_index(ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "Not surprisingly, a considerably larger proportion of female passengers survived when compared to male passengers. Let's check the strength of the correlation between survival and being female. Note that both <em>survived</em> and <em>female</em> can only take on values of 0 or 1. This is known as a <strong>bivariate association and not a correlation</strong>. Furthermore, if one feature is continuous and the other can only take on a value of 0 or 1, it would be a <strong>point-biserial correlation</strong> (Pearson correlation can be applied for this calculation). While we can still use Pearson correlation get a somewhat similar result, <strong>it is more appropriate to use the <a href=\"https://en.wikipedia.org/wiki/Phi_coefficient\">phi coefficient</a> in cases like these.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# using Pearson correlation\n",
    "titanic_corr = titanic.corr(method = 'pearson').round(decimals = 4)\n",
    "\n",
    "\n",
    "# checking results\n",
    "titanic_corr.loc[ : , 'survived' ].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# using the phi coefficient for correlation\n",
    "titanic_phi_corr = titanic.phik_matrix().round(decimals = 4)\n",
    "\n",
    "\n",
    "# checking results\n",
    "titanic_phi_corr.loc[ : , 'survived' ].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "In short, Pearson correlation is for continuous features and the phi coefficient is for non-continuous features. This is taken advantage of in the code below. Note that <em>survived</em> is in both sets since it is the response variable.<br>\n",
    "\n",
    "<h4>a) Complete the code below to develop Pearson correlations and phi coefficients for the appropriate features.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# creating feature sets\n",
    "continuous     = ['survived', 'age', 'fare']\n",
    "\n",
    "non_continuous = ['survived', 'sibsp', 'parch', 'm_age', 'm_cabin',\n",
    "                  'm_boat','m_home_dest', 'potential_youth', 'under_18',\n",
    "                  'number_of_names', 'pclass_1', 'pclass_2', 'pclass_3',\n",
    "                  'female', 'male']\n",
    "\n",
    "\n",
    "# pearson correlation\n",
    "titanic_corr = titanic[ _____ ]._____.round(decimals = 4)\n",
    "\n",
    "\n",
    "# phi coefficient\n",
    "titanic_phi_corr = titanic[ _____ ]._____.round(decimals = 4)\n",
    "\n",
    "\n",
    "# checking results\n",
    "print(f\"\"\"\n",
    "Point-Biserial Correlations\n",
    "---------------------------\n",
    "{titanic_corr.loc[ : , 'survived' ].sort_values(ascending = False)}\n",
    "\n",
    "\n",
    "Phi Coefficients\n",
    "----------------\n",
    "{titanic_phi_corr.loc[ : , 'survived' ].sort_values(ascending = False)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# creating feature sets\n",
    "continuous     = ['survived', 'age', 'fare']\n",
    "\n",
    "non_continuous = ['survived', 'sibsp', 'parch', 'm_age', 'm_cabin',\n",
    "                  'm_boat','m_home_dest', 'potential_youth', 'under_18',\n",
    "                  'number_of_names', 'pclass_1', 'pclass_2', 'pclass_3',\n",
    "                  'female', 'male']\n",
    "\n",
    "\n",
    "# pearson correlation\n",
    "titanic_corr = titanic[ continuous ].corr(method = 'pearson').round(decimals = 4)\n",
    "\n",
    "\n",
    "# phi coefficient\n",
    "titanic_phi_corr = titanic[ non_continuous ].phik_matrix(interval_cols = non_continuous).round(decimals = 4)\n",
    "\n",
    "\n",
    "# checking results\n",
    "print(f\"\"\"\n",
    "Point-Biserial Correlations\n",
    "---------------------------\n",
    "{titanic_corr.loc[ : , 'survived' ].sort_values(ascending = False)}\n",
    "\n",
    "\n",
    "Phi Coefficients\n",
    "----------------\n",
    "{titanic_phi_corr.loc[ : , 'survived' ].sort_values(ascending = False)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part III - Preparing for Logistic Regression</h2><br>\n",
    "The dataset has been prepared with the exception of transformations and standardization. Note that the steps to prepare the dataset are available in <strong>Preparing the Titanic Dataset</strong>, in case you are interested in learning more about this.\n",
    "<br><br>\n",
    "<h3>Transformations</h3><br>\n",
    "As with the linear regression models covered in Computational Analytics, the data should be treated for skewness before modeling. However, instead of using <em>np.log1p()</em>, let's instead apply the <strong>Yeo-Johnson transformation</strong>, which is mathematically defined as follows:\n",
    "<br><br><br>\n",
    "\n",
    "<div style = \"width:image width px; font-size:80%; text-align:center;\"><img src= \"./documentation/yeo_johnson_transformation.png\" width=\"400\" height=\"200\" style=\"padding-bottom:0.0em;\"></div>\n",
    "\n",
    "<br><br>\n",
    "In other words it's a more sophisticated version of <em>np.log1p()</em> that has two major advantages:\n",
    "\n",
    "1. It can transform zeros and negative values.\n",
    "2. It has a regularization parameter, giving it ability to change the degree of transformation in order to achieve better results.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "help(power_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "Run the following codes to transform the x-data using the Yeo-Johnson method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# subsetting X-data\n",
    "x_data = titanic.loc[ : , 'age': ]\n",
    "\n",
    "\n",
    "# checking skewness\n",
    "x_data.skew().round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# yeo-johnson transformation\n",
    "x_transformed = power_transform(X           = x_data,\n",
    "                                method      = 'yeo-johnson',\n",
    "                                standardize = True        )\n",
    "\n",
    "\n",
    "# storing results as a DataFrame\n",
    "x_transformed_df = pd.DataFrame(data    = x_transformed,\n",
    "                                columns = list(x_data.columns))\n",
    "\n",
    "\n",
    "# checking skewness results\n",
    "x_transformed_df.skew().round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "Notice that the Yeo-Johnson transformation effected skewness for continuous and interval data, but not for binary or categorical data. Run the code below to observe this more clearly. Furthermore, in each case that the transformation was applied to the continuous data, skewness got closer to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# calculating difference in skewness\n",
    "print(f\"\"\"\n",
    "Normality Improvements (Skewness)\n",
    "---------------------------------\n",
    "{abs(x_data.skew().round(decimals = 2)) - abs(x_transformed_df.skew().round(decimals = 2))}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h3>Standardization</h3><br>\n",
    "Run the following codes to standardize the data (important in classification modeling). Even though this was done inside the <em>power_trainsform(&nbsp;)</em> method, it is important to re-standardize the data before modeling (even after a transformation).\n",
    "<br><br>\n",
    "Remember, scaling does not affect correlation, phi coefficients, or skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "help(standard_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# standardizing X-data (st = scaled and transformed)\n",
    "x_data_st = standard_scaler(df = x_transformed_df)\n",
    "\n",
    "\n",
    "# checking results\n",
    "x_data_st.describe(include = 'number').round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part IV - Logistic Regression</h2><br>\n",
    "Much can be said about the power of feature engineering, but in general, <font color='red'><strong>good thinking will always beat statistics</strong></font>.<br><br>\n",
    "\n",
    "<br>\n",
    "<strong>Stratifying the Response Variable</strong><br>\n",
    "When working with classification problems, preserving the balance of the response variable is critically important. In terms of the Titanic dataset, we need to preserve the proportion of people that survived in both the training and testing sets. This can be accomplished by using the <em>stratify</em> argument of <strong>train_test_split(&nbsp;)</strong>. The code below will output the original balance between those that survived and those that did not survive the Titanic disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# survival proportions\n",
    "titanic.loc[ : ,'survived'].value_counts(normalize = True).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>a) Preparing Explanatory and Response Data</h4>\n",
    "Instantiate the X-features as <strong>titanic_data</strong> and the response variable (&nbsp;<em>survived</em>&nbsp;) as <strong>titanic_target</strong>.<br><br>\n",
    "<em><strong>Hint:</strong> Use the DataFrame where the x-data has already been transformed and scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "titanic_data   = _____\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "titanic_target = _____\n",
    "\n",
    "\n",
    "## this code will not produce an output ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "titanic_data = x_data_st\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "titanic_target = titanic.loc[ : , 'survived']\n",
    "\n",
    "\n",
    "## this code will not produce an output ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>b) Complete and run the following code to split the data into training and testing sets.</h4>\n",
    "Notice the new stratify argument. This helps preserve the balance of the response variable in the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            titanic_data,\n",
    "            titanic_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = _____) # preserving balance\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "titanic_train = pd.concat([x_train, y_train], axis = 1)\n",
    "\n",
    "\n",
    "## this code will not produce an output ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            titanic_data,\n",
    "            titanic_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = titanic_target) # preserving balance\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "titanic_train = pd.concat([x_train, y_train], axis = 1)\n",
    "\n",
    "\n",
    "## this code will not produce an output ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>c) Build a Univariate Logistic Regression Model</h4>\n",
    "Build a logistic regression model in <strong>statsmodels</strong> using the x-feature that has the strongest relationship with the response variable (&nbsp;<em>survived</em>&nbsp;)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\" _____ \"\"\",\n",
    "                           data = titanic_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small._____\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula = \"\"\"survived ~ m_boat\"\"\",\n",
    "                           data    = titanic_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>d) Build a logistic regression model in statsmodels using all of the explanatory variables.</h4>\n",
    "Use the loop below for efficiency and correct any errors that occur after the copy/paste.<br><br>\n",
    "<em><strong>Hint:</strong> Remember to remove one column for each one-hot encoded feature so that the model computes properly.</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "for val in titanic_data:\n",
    "    print(f\" {val} + \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\" _____ \"\"\",\n",
    "                                        data    = titanic_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\"  survived ~\n",
    "                                         age + \n",
    "                                         sibsp + \n",
    "                                         parch + \n",
    "                                         fare + \n",
    "                                         m_age + \n",
    "                                         m_cabin + \n",
    "                                         m_boat + \n",
    "                                         m_home_dest + \n",
    "                                         potential_youth + \n",
    "                                         under_18 + \n",
    "                                         number_of_names + \n",
    "                                         pclass_1 + \n",
    "                                         pclass_2 + \n",
    "                                         female\"\"\",\n",
    "                                         data    = titanic_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part V - Refocusing the Response Variable</h2><br>\n",
    "<strong>m_boat</strong> is performing incredibly well in predicting passenger survival. This aligns with common sense as getting into a lifeboat means staying out of the frigid waters, avoiding causes of death like hypothermia and drowning. This feature is so powerful and interpretable that there is little reason to develop a more complex model. <strong>Survival depends on getting into a life boat.</strong>\n",
    "<br><br>\n",
    "Let's shift the focus of our modeling efforts to factors that contribute to getting into a lifeboat. Thus, we will change our response variable from <strong>survived</strong> to <strong>m_boat</strong>. Note that <strong>survived</strong> should not be used in the model as it takes place after the event horizon. In the interest of time, the following full model has been developed for you.\n",
    "<br><br>\n",
    "One task stands in our way before using <strong>m_boat</strong> as the response variable. Since it was transformed, it is no longer in binary form (0 or 1). Therefore, we need to do some preparation before we are ready to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# unique values for m_boat\n",
    "titanic_train['m_boat'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# converting m_boat back to 0s and 1s\n",
    "for index, value in titanic_train.iterrows():\n",
    "    \n",
    "    if   titanic_train.loc[ index, 'm_boat' ] < 0:\n",
    "          titanic_train.loc[ index, 'm_boat' ] = 0\n",
    "    \n",
    "    elif titanic_train.loc[ index, 'm_boat' ] > 0:\n",
    "          titanic_train.loc[ index, 'm_boat' ] = 1\n",
    "            \n",
    "    else:\n",
    "        print('Something went wrong.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# new unique values for m_boat\n",
    "titanic_train['m_boat'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logit_full = smf.logit(formula = \"\"\" m_boat ~\n",
    "                                     age +\n",
    "                                     sibsp +\n",
    "                                     parch +\n",
    "                                     fare +\n",
    "                                     m_age +\n",
    "                                     m_cabin +\n",
    "                                     m_home_dest +\n",
    "                                     potential_youth +\n",
    "                                     under_18 +\n",
    "                                     number_of_names +\n",
    "                                     pclass_1 +\n",
    "                                     pclass_2 +\n",
    "                                     pclass_3 +\n",
    "                                     female +\n",
    "                                     male\"\"\",\n",
    "                                     data    = titanic_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "logit_full = logit_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "logit_full. summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>a) Develop a model where all features are significant based on their p-values.</h4>\n",
    "Based on the output above, remove all features that were deemed insignificant based on their p-values. Once finished, check the p-values again to ensure significance.<br><br>\n",
    "<strong>Note:</strong> 'nan' is also considered insignificant (excluding the intercept, which must always be included in the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logit_sig = smf.logit(formula = \"\"\" _____ \"\"\",\n",
    "                                            data    = titanic_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "logit_sig = logit_sig.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "logit_sig.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logit_sig = smf.logit(formula = \"\"\" m_boat ~\n",
    "                                    age +\n",
    "                                    m_cabin +\n",
    "                                    number_of_names +\n",
    "                                    pclass_2 +\n",
    "                                    pclass_3 +\n",
    "                                    female\"\"\",\n",
    "                                    data    = titanic_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "logit_sig = logit_sig.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "logit_sig.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part V: Logistic Regression in scikit-learn</h2><br>\n",
    "We can use the model above as a candidate model. In an effort to stay organized, we can put each candidate model into a dictionary. Run the code below to instantiate a dictionary to store the x-side of each candidate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['age', 'sibsp', 'parch', 'fare', 'm_age', 'm_cabin',\n",
    "                   'm_home_dest', 'potential_youth', 'under_18',\n",
    "                   'number_of_names', 'pclass_1', 'pclass_2', 'female'],\n",
    " \n",
    "\n",
    " # p-value significant variables only\n",
    " 'logit_sig'  : ['age', 'm_cabin', 'number_of_names',\n",
    "                 'pclass_2', 'pclass_3', 'female'   ]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>a) Dynamically print each feature set.</h4>\n",
    "Complete the code to display each feature set in <strong>candidate_dict</strong>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# printing candidate variable sets\n",
    "_____(_____\"\"\"\n",
    "/--------------------------\\\\\n",
    "|Explanatory Variable Sets |\n",
    "\\\\--------------------------/\n",
    "\n",
    "Full Model:\n",
    "-----------\n",
    "{_____}\n",
    "\n",
    "\n",
    "Significant p-value Model:\n",
    "--------------------------------\n",
    "{_____}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# printing candidate variable sets\n",
    "print(f\"\"\"\n",
    "/--------------------------\\\\\n",
    "|Explanatory Variable Sets |\n",
    "\\\\--------------------------/\n",
    "\n",
    "Full Model:\n",
    "-----------\n",
    "{candidate_dict['logit_full']}\n",
    "\n",
    "\n",
    "Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig']}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<strong>Regression v. Classification in scikit-learn</strong><br>\n",
    "One of the many great things about working with scikit-learn is that classification modeling follows the same approach as regression modeling.\n",
    "<br>\n",
    "<h4>b) Build a logistic regression model in scikit-learn</h4>\n",
    "Build a logistic regression model in scikit-learn using the <strong>logit_sig</strong> X-features and <strong>m_boat</strong> as the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# train/test split with the full model\n",
    "titanic_data   =  x_data_st[ _____ ]\n",
    "titanic_target =  titanic  [ _____ ]\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            titanic_data,\n",
    "            titanic_target,\n",
    "            random_state = 702,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = titanic_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# train/test split with the full model\n",
    "titanic_data   =  x_data_st[ candidate_dict['logit_sig'] ]\n",
    "titanic_target =  titanic  [ 'm_boat']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            titanic_data,\n",
    "            titanic_target,\n",
    "            random_state = 702,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = titanic_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a logistic regression model\n",
    "logreg = sklearn.linear_model.LogisticRegression(solver = 'lbfgs',\n",
    "                                                 C = 1,\n",
    "                                                 random_state = 702)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "train_score = round(logreg_fit.score(x_train, y_train), ndigits = 4) # train accuracy\n",
    "test_score  = round(logreg_fit.score(x_test, y_test),   ndigits = 4) # test accuracy\n",
    "tt_gap      = round(abs(train_score - test_score),      ndigits = 4) # gap\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print(f\"\"\"\\\n",
    "Training ACCURACY: {train_score}\n",
    "Testing  ACCURACY: {test_score}\n",
    "Train-Test Gap   : {tt_gap}\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part VI: Why Accuracy is Bad</h2><br>\n",
    "What does it mean to be accurate? Mathematically, predictive accuracy can be calculated as follows:<br><br>\n",
    "\n",
    "~~~\n",
    "correct predictions / total predictions\n",
    "~~~\n",
    "\n",
    "<br>\n",
    "However, such a calculation poses a problem. Let's say, for example, that we went back to predicting whether a passenger survived the Titanic disaster. If we were to run the following code:<br><br>\n",
    "\n",
    "~~~\n",
    "titanic['survived'].mean()\n",
    "~~~\n",
    "\n",
    "<br>\n",
    "We would learn that approximately 42% of the passengers in the dataset survived. Therefore, if we were to claim that every passenger survived, we would have an accuracy of 42%, even though we are 100% inaccurate in terms of predicting passengers that did not survive. This becomes an even more serious problem when the response variable is heavily imbalanced, for example, when 90% of observations experienced a phenomenon. Therefore, we need to consider accuracy from two perspectives: positive cases (the 1s) and negative cases (the 0s). In this section, we will cover tools that more appropriately measure classification model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>\n",
    "<h3>The Confusion Matrix</h3><br>\n",
    "The confusion matrix in Python can be read as follows:<br><br>\n",
    "\n",
    "~~~\n",
    "                   |\n",
    "  True Negatives   |  False Positives\n",
    "  (correct)        |  (incorrect)\n",
    "                   |\n",
    "-------------------|------------------\n",
    "                   |\n",
    "  False Negatives  |  True Positives\n",
    "  (incorrect)      |  (correct)\n",
    "                   |\n",
    "~~~\n",
    "\n",
    "<br><br><br>\n",
    "In terms of our model:<br>\n",
    "\n",
    "~~~\n",
    "                                                 |\n",
    "  PREDICTED: GOT IN LIFEBOAT (m_boat=0)          |  PREDICTED: DID NOT GET IN LIFEBOAT (m_boat=1)\n",
    "  ACTUAL:    GOT IN LIFEBOAT (m_boat=0)          |  ACTUAL:    GOT IN LIFEBOAT         (m_boat=0)\n",
    "                                                 |\n",
    "-------------------------------------------------|-----------------------------------------------\n",
    "                                                 |\n",
    "  PREDICTED: GOT IN LIFEBOAT         (m_boat=0)  |  PREDICTED: DID NOT GET IN LIFEBOAT (m_boat=1)\n",
    "  ACTUAL:    DID NOT GET IN LIFEBOAT (m_boat=1)  |  ACTUAL:    DID NOT GET IN LIFEBOAT (m_boat=1)\n",
    "                                                 |  \n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# creating a confusion matrix\n",
    "print(confusion_matrix(y_true = y_test,\n",
    "                       y_pred = logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<strong>Visualized Confusion Matrix</strong><br>\n",
    "Run the code below to apply the user defined function <em>visual_cm(&nbsp;)</em>, which will generate a visualization of the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calling the visual_cm function\n",
    "visual_cm(true_y = y_test,\n",
    "          pred_y = logreg_pred,\n",
    "          labels = ['Life Boat', 'Not In Life Boat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h3>MUST KNOW: Area Under The Curve (AUC)</h3><br>\n",
    "The area under the curve (AUC) value is one of the most common metrics used to evaluate the overall performance of a classification model. This is largely due to the fact that this metric takes into account two key factors:<br><br>\n",
    "<u>Sensitivity</u><br>\n",
    "Number of times the model predicted that an event WOULD occur compared to the number of times the event DID occur.\n",
    "<br><br>\n",
    "<u>Specificity</u><br>\n",
    "Number of times the model predicted that an event WOULD NOT occur compared to the number of times the event DID NOT occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# preparing AUC, precision, and recall\n",
    "auc       = round(roc_auc_score(y_true = y_test, y_score = logreg_pred) , ndigits = 4)\n",
    "precision = round(precision_score(y_true = y_test, y_pred = logreg_pred), ndigits = 4)\n",
    "recall    = round(recall_score(y_true = y_test, y_pred = logreg_pred)   , ndigits = 4)\n",
    "\n",
    "\n",
    "# dynamically printing metrics\n",
    "print(f\"\"\"\\\n",
    "AUC:       {auc}\n",
    "Precision: {precision}\n",
    "Recall:    {recall}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "Run the code below to observe the model's coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "model_values = zip(titanic[candidate_dict[ 'logit_sig'] ].columns,\n",
    "                           logreg_fit.coef_.ravel().round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "model_lst = [('intercept', round(logreg_fit.intercept_[0], ndigits = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in model_values:\n",
    "    model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part VII: Adjusting The Classification Threshold</h2><br>\n",
    "In this final section, we will adjust the <strong>classification threshold</strong>, or the boundary between predicting a one or a zero. By default, if an observation has a predicted probability at or above 0.50, it will be predicted as being a member of the 1 class. Adjusting this threshold may lead to better predictions or better alignment with real-world applications. This is particularly effective when attempting to control sensitivity or specificity as it is likely to lead to less false positives or false negatives, depending on the direction the threshold is changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# printing the predicted probabilities of 0 and 1, respectively\n",
    "pd.DataFrame(data = logreg_fit.predict_proba(titanic_data).round(decimals = 2),\n",
    "             columns = ['Class 0', 'Class 1']).head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# printing actual predictions (0 or 1)\n",
    "pd.DataFrame(data    = logreg_fit.predict(titanic_data),\n",
    "             columns = ['Predicted Class']).head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# storing objects for predictions and true y values\n",
    "true_y         = titanic_target\n",
    "pred_probs     = pd.DataFrame(logreg_fit.predict_proba(titanic_data)).round(decimals = 2)\n",
    "pred_thresh_50 = pd.DataFrame(logreg_fit.predict(titanic_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# combining the predictions into a DataFrame and renaming columns\n",
    "prediction_df = pd.concat([true_y, pred_probs, pred_thresh_50], axis = 1)\n",
    "prediction_df.columns = ['true_y', 'prob_0', 'prob_1', 'pred_thresh_50',]\n",
    "\n",
    "\n",
    "# checking results\n",
    "prediction_df.head(n = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = prediction_df['true_y'],\n",
    "                             y_pred = prediction_df['pred_thresh_50']).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# probability of 1 >= 0.25\n",
    "prediction_df['pred_thresh_25'] = (prediction_df['prob_1'] >= 0.25).astype(dtype = int)\n",
    "\n",
    "\n",
    "# checking results\n",
    "prediction_df.tail(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = prediction_df['true_y'],\n",
    "                             y_pred = prediction_df['pred_thresh_25']).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "~~~\n",
    "\n",
    " __     __                 ____ _                     _ \n",
    " \\ \\   / /__ _ __ _   _   / ___| | __ _ ___ ___ _   _| |\n",
    "  \\ \\ / / _ \\ '__| | | | | |   | |/ _` / __/ __| | | | |\n",
    "   \\ V /  __/ |  | |_| | | |___| | (_| \\__ \\__ \\ |_| |_|\n",
    "    \\_/ \\___|_|   \\__, |  \\____|_|\\__,_|___/___/\\__, (_)\n",
    "                  |___/                         |___/   \n",
    "                  \n",
    "~~~\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
