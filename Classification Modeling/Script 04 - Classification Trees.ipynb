{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<br><h2>Script 04 | Classification Trees</h2>\n",
    "<br>\n",
    "Written by Chase Kusterer<br>\n",
    "<a href=\"https://github.com/chase-kusterer\">GitHub</a> | <a href=\"https://www.linkedin.com/in/kusterer/\">LinkedIn</a>\n",
    "<br><br><br>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<h2>Part I: Preparing to Model</h2>\n",
    "<h4>a) Imports and Loading the Dataset</h4>\n",
    "Complete the code to import packages and load the 'titanic_feature_rich.xlsx' dataset into Python as <strong>titanic</strong>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "## Package Imports ##\n",
    "# fundamentals\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "import warnings\n",
    "\n",
    "# scaling and scoring\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.metrics import make_scorer               # customizable scorer\n",
    "\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "\n",
    "\n",
    "## Data Import ##\n",
    "titanic = _____\n",
    "\n",
    "\n",
    "## Options ##\n",
    "# setting pandas print options and supressing warnings\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "warnings.simplefilter(action = 'ignore', category = UserWarning)\n",
    "\n",
    "\n",
    "## Results ##\n",
    "# displaying the head of the dataset\n",
    "titanic.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "## Package Imports ##\n",
    "# fundamentals\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "import warnings\n",
    "\n",
    "# scaling and scoring\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.metrics import make_scorer               # customizable scorer\n",
    "\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "\n",
    "\n",
    "## Data Import ##\n",
    "titanic = pd.read_excel('./datasets/titanic_feature_rich.xlsx')\n",
    "\n",
    "\n",
    "## Options ##\n",
    "# setting pandas print options and supressing warnings\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "warnings.simplefilter(action = 'ignore', category = UserWarning)\n",
    "\n",
    "\n",
    "## Results ##\n",
    "# displaying the head of the dataset\n",
    "titanic.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>b) Make the lifeboat feature more user friendly.</h4>\n",
    "Write a code to reverse <em>m_boat</em>. In other words, the original zeros should be ones and the original ones should be zeroes. Note that <strong>this is a classic technical interview question</strong>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# reversing m_boat\n",
    "titanic['lifeboat'] = _____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# reversing m_boat\n",
    "titanic['lifeboat'] = abs(titanic['m_boat'] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# checking results\n",
    "titanic[  ['m_boat', 'lifeboat']  ].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<strong>User-Defined Functions</strong><br>\n",
    "Run the following code to load the user-defined functions used throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     171,
     197
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "## sklearn_summary ##\n",
    "#####################\n",
    "def classification_summary(x,\n",
    "                           y,\n",
    "                           model,\n",
    "                           model_name   = \"\",\n",
    "                           results_df   = None,\n",
    "                           tt_split     = True,\n",
    "                           test_size    = 0.25,\n",
    "                           scale        = False,\n",
    "                           full_tree    = False,\n",
    "                           random_state = 702):\n",
    "    \"\"\"  \n",
    "    This function is designed to generate summary statistics for the following\n",
    "    classification models from scikit-learn:\n",
    "    * LogisticRegression         - Logistic Regression\n",
    "    * DecisionTreeClassifier     - Classification Tree\n",
    "    * RandomForestClassifier     - Random Forest\n",
    "    * GradientBoostingClassifier - Gradient Boosted Machine\n",
    "\n",
    "\n",
    "    Additional Functionality\n",
    "    ------------------------\n",
    "    This function will standardize the data using StandardScaler() and create\n",
    "    training and testing sets using train-test split, stratifying the\n",
    "    y-variable.\n",
    "    \n",
    "    It will also output a tabular confusion matrix, calculate area under the\n",
    "    ROC curve (AUC) for the training and testing sets, as well as the train-\n",
    "    test gap.\n",
    "    \n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    x            | array     | X-data before train-test split | No default.\n",
    "    y            | array     | y-data before train-test split | No default.\n",
    "    model        | model     | model object to instantiate    | No default.\n",
    "    model_name   | str       | option to name the model       | Default = \"\"\n",
    "    results_df   | DataFrame | place to store model results   | Default = None\n",
    "    test_size    | float     | test set proportion            | Default = 0.25\n",
    "    scale        | bool      | whether to scale the data      | Default = False\n",
    "    random_state | int       | seed for train-test split      | Default = 702\n",
    "    \"\"\"\n",
    "    \n",
    "    ###########\n",
    "    # scaling #\n",
    "    ###########\n",
    "    \n",
    "    if scale == True:\n",
    "        # instantiating a StandardScaler() object\n",
    "        scaler = StandardScaler(copy = True)\n",
    "\n",
    "\n",
    "        # FITTING the scaler with the data\n",
    "        scaler.fit(x)\n",
    "\n",
    "        # TRANSFORMING our data after fit\n",
    "        x_scaled = scaler.transform(x)\n",
    "\n",
    "        # converting scaled data into a DataFrame\n",
    "        x_scaled_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "        # reattaching column names\n",
    "        x_scaled_df.columns = list(x.columns)\n",
    "\n",
    "        # reverting back to x as the DataFrame's name\n",
    "        x = x_scaled_df\n",
    "    \n",
    "    \n",
    "    ####################\n",
    "    # train-test split #\n",
    "    ####################\n",
    "    # standard train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, # x\n",
    "                                                        y, # y\n",
    "                                                        test_size    = test_size,\n",
    "                                                        random_state = random_state,\n",
    "                                                        stratify     = y)\n",
    "    \n",
    "    \n",
    "    #########################\n",
    "    # fit - predict - score #\n",
    "    #########################\n",
    "    # fitting to training data\n",
    "    model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    # predicting on new data\n",
    "    model_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "    # scoring results\n",
    "    model_train_auc   = round(roc_auc_score(y_true  = y_train,\n",
    "                              y_score = model.predict(x_train)), ndigits = 4) # auc\n",
    "    \n",
    "    model_test_auc    = round(roc_auc_score(y_true  = y_test,\n",
    "                              y_score = model.predict(x_test)),  ndigits = 4) # auc\n",
    "\n",
    "    model_gap         = round(abs(model_train_auc - model_test_auc), ndigits = 4)\n",
    "\n",
    "    \n",
    "    ####################\n",
    "    # confusion matrix #\n",
    "    ####################\n",
    "    full_tree_tn, \\\n",
    "    full_tree_fp, \\\n",
    "    full_tree_fn, \\\n",
    "    full_tree_tp = confusion_matrix(y_true = y_test, y_pred = model_pred).ravel()\n",
    "\n",
    "    \n",
    "    ###########################\n",
    "    # storing/showing results #\n",
    "    ###########################\n",
    "    # instantiating a list to store model results\n",
    "    results_lst = [ model_name, model_train_auc, model_test_auc, model_gap ]\n",
    "\n",
    "    # converting to DataFrame\n",
    "    results_lst = pd.DataFrame(data = results_lst)\n",
    "\n",
    "    # transposing (rotating) DataFrame\n",
    "    results_lst = np.transpose(a = results_lst)\n",
    "    \n",
    "    # if no results DataFrame provided\n",
    "    if results_df == None:\n",
    "\n",
    "        # concatenating to coef_df\n",
    "        results_df = pd.DataFrame(data = results_lst)\n",
    "    \n",
    "    # if results DataFrame provided\n",
    "    else:\n",
    "        \n",
    "        # concatenating to coef_df\n",
    "        results_df = pd.concat(objs = [results_df, results_lst],\n",
    "                               axis         = 0,\n",
    "                               ignore_index = True)\n",
    "        \n",
    "    # adding column names\n",
    "    results_columns = ['Model Name', 'train_auc', 'test_auc', 'tt_gap']\n",
    "    \n",
    "    # renaming columns\n",
    "    results_df.columns = results_columns\n",
    "    \n",
    "    \n",
    "    print(f\"\"\"\n",
    "    Results for {model_name}\n",
    "    {'=' * 20}\n",
    "    Model Type: {model}\n",
    "    Training Samples: {len(x_train)} \n",
    "    Testing  Samples: {len(x_test)}\n",
    "    \n",
    "    \n",
    "    Summary Statistics\n",
    "    ------------------\n",
    "    AUC (Train): {model_train_auc}\n",
    "    AUC (Test) : {model_test_auc}\n",
    "    TT Gap     : {model_gap}\n",
    "    \n",
    "    \n",
    "    Confusion Matrix (test set)\n",
    "    ---------------------------\n",
    "    True Negatives : {full_tree_tn}\n",
    "    False Positives: {full_tree_fp}\n",
    "    False Negatives: {full_tree_fn}\n",
    "    True Positives : {full_tree_tp}\n",
    "    \"\"\")\n",
    "    \n",
    "\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    labels : DataFrame with labels (i.e., x_data)\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_data.shape[1]\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Feature_Importance_Plot.png')\n",
    "        \n",
    "        \n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "    Creates a visualization of a confusion matrix.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    true_y : true values for the response variable\n",
    "    pred_y : predicted values for the response variable\n",
    "    labels : , default None\n",
    "        \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "help(classification_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part II: Classification Trees (CART Models)</h2><br>\n",
    "CART models are very useful in classification problems as they output interesting tools such as <strong>tree plots</strong> and <strong>feature importance</strong>. As they are a nonparametric model type, they have no coefficients. <font 'color=red'><strong>They also assume no model form, meaning that we do not need to transform any features or engineer new ones.</strong></font> CART models are meant to work out of the box.<br><br>\n",
    "\n",
    "<strong>CART Model Highlights</strong><br>\n",
    "\n",
    "* tend to overfit unless pruned\n",
    "* tend to be worse at prediction than other model types (after pruning)\n",
    "* can generate very useful outputs for developing hypotheses and data-driven findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# preparing to partition data\n",
    "x_data   =  titanic.drop(['survived', 'm_boat', 'lifeboat',\n",
    "                          'male', 'pclass_3'],\n",
    "                               axis = 1)\n",
    "\n",
    "\n",
    "y_data =  titanic['lifeboat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Full Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "You may be wondering what just happened. CART models are supposed to work out of the box, and the one we just built is severely overfit. Let me make a correction to what was stated above: CART models are supposed to work out of the box <strong>if they are tuned properly</strong>. Just like gardening in real life, our decision tree needs some love. We've let it grow out of control and now it's so big that its destroying our predictions and covering up our insights. Let's take a closer look at what we've just created.\n",
    "<br><br>\n",
    "Run the following code generate a visual tree output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# setting figure size\n",
    "plt.figure(figsize=(150,50))\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model, \n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 14)\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "The visual above may remind you of a world map. Unfortunately, this is not the goal of classification tree models. We need to <strong>prune the tree</strong> (limit its layers of growth) in order to better analyze our visual output. This will also help prevent the model from overfitting as it will be unable to continually split the training data into nodes until each terminal node is as pure as it can be (often results in each observation being in its own terminal node).<br><br>\n",
    "<h4>b) Develop a new classificaion tree model.</h4>\n",
    "Develop a classification tree with a maximum depth of 4. Below is a link to the model type's documentation for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "help(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = 4,\n",
    "                                    random_state     = 708)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Pruned Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# setting figure size\n",
    "plt.figure(figsize=(22, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 12) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "CART models have an amazing tool to help evaluate a model's features. This tool, known as <strong>feature importance</strong>, informs as to how \"important\" each feature is in terms of splitting the data into nodes. Run the user-defined function below to see the results of this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "help(plot_feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(model  = tree_model,\n",
    "                         train  = x_data,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part III: Using Classification Trees For Analysis</h2><br>\n",
    "Tree plots can be very useful in data exploration. Let's practice by analyzing how age plays a factor in terms of getting into a lifeboat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "## consolidating code into one cell ##\n",
    "\n",
    "# preparing to partition data\n",
    "x_data =  titanic[ ['age'] ]\n",
    "\n",
    "\n",
    "y_data =  titanic['lifeboat']\n",
    "\n",
    "\n",
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = 4,\n",
    "                                    random_state     = 708)\n",
    "\n",
    "\n",
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Age Tree\")\n",
    "\n",
    "\n",
    "# setting figure size\n",
    "plt.figure(figsize=(16, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 12) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "As indicated above, it appears that there are no age groups with a definite chance of getting into a lifeboat. Let's dig deeper by looking into additional factors, such as gender and passenger class.\n",
    "\n",
    "<strong>a) Complete the code to instantiate a tree model using <em>age</em>, <em>gender</em>, and <em>passenger class</em>.</strong><br>\n",
    "Additionally, adjust the <em>max_depth</em> and <em>min_samples_leaf</em> hyperparameters to stabilize your model (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# checking feature names\n",
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# All features of interest in the same tree #\n",
    "#############################################\n",
    "\n",
    "# preparing to partition data\n",
    "x_data =  _____\n",
    "\n",
    "\n",
    "y_data =  titanic['lifeboat']\n",
    "\n",
    "\n",
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = _____,\n",
    "                                    min_samples_leaf = _____,\n",
    "                                    random_state     = 708)\n",
    "\n",
    "\n",
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Age Tree\")\n",
    "\n",
    "\n",
    "# setting figure size\n",
    "plt.figure(figsize=(20, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 12) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# All features of interest in the same tree #\n",
    "#############################################\n",
    "\n",
    "\n",
    "# preparing to partition data\n",
    "x_data =  titanic[ ['age', 'female', 'pclass_1', 'pclass_2'] ]\n",
    "\n",
    "\n",
    "y_data =  titanic['lifeboat']\n",
    "\n",
    "\n",
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = 4,\n",
    "                                    min_samples_leaf = 30,\n",
    "                                    random_state     = 708)\n",
    "\n",
    "\n",
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Age Tree\")\n",
    "\n",
    "\n",
    "# setting figure size\n",
    "plt.figure(figsize=(18, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 14) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<strong>b) Interpret your model's tree plot in the space below.</strong>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Use this space to write your interpretation."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "The model immediately split on female. After this split, we have one tree for each gender. The left side represents the male gender and the right side represents the female gender.\n",
    "\n",
    "Notice the predominately orange color of the male passenger tree. This indicates that most male passengers did not get into a lifeboat. This is evident regardless of passenger class. However, younger male passengers (where age is less than or equal to thirteen years and six months) have approximately a 67% chance of getting into a lifeboat.\n",
    "\n",
    "On the female passenger tree, notice that almost every box is blue. This implies that most female passengers got into a lifeboat. The chances were much more in favor of first class passengers, followed by those in second class. Third class passengers, on the other hand, were much less likely to get into a lifeboat, especially if over the age of twenty five."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part IV: Further Analysis</h2><br>\n",
    "Tree plots can be very useful in data exploration. Let's practice by analyzing how age plays a factor in terms of getting into a lifeboat.\n",
    "\n",
    "<strong>a) Complete the code to instantiate a tree model using <em>age</em>, <em>gender</em>, and <em>passenger class</em>.</strong><br>\n",
    "Additionally, adjust the <em>max_depth</em> and <em>min_samples_leaf</em> hyperparameters to stabilize your model (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "# Subset: Female and First Class #\n",
    "##################################\n",
    "\n",
    "# preparing to partition data\n",
    "x_data =  titanic.loc[ : , ['age'] ][ titanic['female'] == 1 ][ titanic['pclass_1'] == 1 ]\n",
    "\n",
    "\n",
    "y_data =  titanic.loc[ : , 'lifeboat'][ titanic['female'] == 1 ][ titanic['pclass_1'] == 1 ]\n",
    "\n",
    "\n",
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = 4,\n",
    "                                    min_samples_leaf = 5,\n",
    "                                    random_state     = 708)\n",
    "\n",
    "\n",
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Age Tree\")\n",
    "\n",
    "\n",
    "# setting figure size\n",
    "plt.figure(figsize=(12, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 12) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "# Subset: Female and Second Class #\n",
    "###################################\n",
    "\n",
    "# preparing to partition data\n",
    "x_data =  titanic.loc[ : , ['age'] ][ titanic['female'] == 1 ][ titanic['pclass_2'] == 1 ]\n",
    "\n",
    "\n",
    "y_data =  titanic.loc[ : , 'lifeboat'][ titanic['female'] == 1 ][ titanic['pclass_2'] == 1 ]\n",
    "\n",
    "\n",
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = 3,\n",
    "                                    min_samples_leaf = 5,\n",
    "                                    random_state     = 708)\n",
    "\n",
    "\n",
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Age Tree\")\n",
    "\n",
    "\n",
    "# setting figure size\n",
    "plt.figure(figsize=(12, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 12) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "# Subset: Female and Third Class #\n",
    "##################################\n",
    "\n",
    "# preparing to partition data\n",
    "x_data =  titanic.loc[ : , ['age'] ][ titanic['female'] == 1 ][ titanic['pclass_3'] == 1 ]\n",
    "\n",
    "\n",
    "y_data =  titanic.loc[ : , 'lifeboat'][ titanic['female'] == 1 ][ titanic['pclass_3'] == 1 ]\n",
    "\n",
    "\n",
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = 2,\n",
    "                                    min_samples_leaf = 30,\n",
    "                                    random_state     = 708)\n",
    "\n",
    "\n",
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Age Tree\")\n",
    "\n",
    "\n",
    "# setting figure size\n",
    "plt.figure(figsize=(12, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 12) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# Subset: Male and First Class #\n",
    "################################\n",
    "\n",
    "# preparing to partition data\n",
    "x_data =  titanic.loc[ : , ['age'] ][ titanic['female'] == 0 ][ titanic['pclass_1'] == 1 ]\n",
    "\n",
    "\n",
    "y_data =  titanic.loc[ : , 'lifeboat'][ titanic['female'] == 0 ][ titanic['pclass_1'] == 1 ]\n",
    "\n",
    "\n",
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = 2,\n",
    "                                    min_samples_leaf = 30,\n",
    "                                    random_state     = 708)\n",
    "\n",
    "\n",
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Age Tree\")\n",
    "\n",
    "\n",
    "# setting figure size\n",
    "plt.figure(figsize=(12, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 12) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# Subset: Male and Second Class #\n",
    "#################################\n",
    "\n",
    "# preparing to partition data\n",
    "x_data =  titanic.loc[ : , ['age'] ][ titanic['female'] == 0 ][ titanic['pclass_2'] == 1 ]\n",
    "\n",
    "\n",
    "y_data =  titanic.loc[ : , 'lifeboat'][ titanic['female'] == 0 ][ titanic['pclass_2'] == 1 ]\n",
    "\n",
    "\n",
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = 3,\n",
    "                                    min_samples_leaf = 30,\n",
    "                                    random_state     = 708)\n",
    "\n",
    "\n",
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Age Tree\")\n",
    "\n",
    "\n",
    "# setting figure size\n",
    "plt.figure(figsize=(12, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 12) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# Subset: Male and Third Class #\n",
    "################################\n",
    "\n",
    "# preparing to partition data\n",
    "x_data =  titanic.loc[ : , ['age'] ][ titanic['female'] == 0 ][ titanic['pclass_3'] == 1 ]\n",
    "\n",
    "\n",
    "y_data =  titanic.loc[ : , 'lifeboat'][ titanic['female'] == 0 ][ titanic['pclass_3'] == 1 ]\n",
    "\n",
    "\n",
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = 4,\n",
    "                                    min_samples_leaf = 5,\n",
    "                                    random_state     = 708)\n",
    "\n",
    "\n",
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Age Tree\")\n",
    "\n",
    "\n",
    "# setting figure size\n",
    "plt.figure(figsize=(12, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 12) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# preparing to partition data\n",
    "x_data =  titanic[ ['age'] ]\n",
    "\n",
    "\n",
    "y_data =  titanic['lifeboat']\n",
    "\n",
    "\n",
    "\n",
    "# instantiating a classification tree\n",
    "tree_model = DecisionTreeClassifier(max_depth        = 4,\n",
    "                                    random_state     = 708)\n",
    "\n",
    "\n",
    "# using the classification_summary function\n",
    "classification_summary(x          = x_data,\n",
    "                       y          = y_data,\n",
    "                       model      = tree_model,\n",
    "                       model_name = \"Age Tree\")\n",
    "\n",
    "\n",
    "\n",
    "# setting figure size\n",
    "plt.figure(figsize=(16, 6)) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = tree_model,\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 12) # adjust if boxes are overlapping\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "~~~\n",
    "      ___  ___  __                 \n",
    "|__/ |__  |__  |__)                \n",
    "|  \\ |___ |___ |                   \n",
    "                                   \n",
    " __   __   __               __    /\n",
    "/ _` |__) /  \\ |  | | |\\ | / _`  / \n",
    "\\__> |  \\ \\__/ |/\\| | | \\| \\__> .  \n",
    "\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
